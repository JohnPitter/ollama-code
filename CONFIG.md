# âš™ï¸ Configuration Guide - Ollama Code

## ğŸ“ LocalizaÃ§Ã£o do Arquivo de ConfiguraÃ§Ã£o

O Ollama Code usa um arquivo JSON para configuraÃ§Ã£o. LocalizaÃ§Ã£o padrÃ£o:

**Linux/macOS:**
```
~/.ollama-code/config.json
```

**Windows:**
```
C:\Users\<seu-usuario>\.ollama-code\config.json
```

## ğŸš€ InicializaÃ§Ã£o AutomÃ¡tica

Na primeira execuÃ§Ã£o, o Ollama Code **automaticamente**:
1. Detecta que nÃ£o existe arquivo de configuraÃ§Ã£o
2. Cria o diretÃ³rio `~/.ollama-code/`
3. Gera `config.json` com valores padrÃ£o
4. Salva o arquivo

VocÃª **nÃ£o precisa** criar manualmente!

## ğŸ“ Estrutura do Arquivo

O arquivo config.json possui 3 seÃ§Ãµes principais:

### 1. Ollama (ConfiguraÃ§Ãµes do Servidor)

```json
{
  "ollama": {
    "url": "http://localhost:11434",
    "model": "qwen2.5-coder:32b-instruct-q6_K",
    "temperature": 0.7,
    "max_tokens": 4096,
    "gpu_layers": 999,
    "num_gpu": 1,
    "max_vram": 16384,
    "num_parallel": 4,
    "flash_attention": true
  }
}
```

**Campos:**
- `url` - URL do servidor Ollama (padrÃ£o: http://localhost:11434)
- `model` - Modelo a ser usado
- `temperature` - Criatividade (0.0-1.0, padrÃ£o: 0.7)
- `max_tokens` - MÃ¡ximo de tokens por resposta
- `gpu_layers` - Layers a carregar na GPU (999 = todas)
- `num_gpu` - NÃºmero de GPUs a usar
- `max_vram` - MÃ¡ximo de VRAM em MB (16384 = 16GB)
- `num_parallel` - RequisiÃ§Ãµes paralelas
- `flash_attention` - Usar flash attention (mais rÃ¡pido)

### 2. App (ConfiguraÃ§Ãµes da AplicaÃ§Ã£o)

```json
{
  "app": {
    "mode": "interactive",
    "work_dir": ".",
    "output_style": "default",
    "enable_colors": true,
    "enable_checkpoints": true,
    "enable_sessions": true,
    "enable_memory": true,
    "checkpoint_retention": 30,
    "max_checkpoints": 100,
    "log_level": "info",
    "log_file": ""
  }
}
```

**Campos:**
- `mode` - Modo padrÃ£o: `readonly`, `interactive`, `autonomous`
- `work_dir` - DiretÃ³rio de trabalho padrÃ£o
- `output_style` - Estilo: `default`, `explanatory`, `learning`, `corporate`
- `enable_colors` - Usar cores no terminal
- `enable_checkpoints` - Habilitar sistema de checkpoints
- `enable_sessions` - Habilitar gerenciamento de sessÃµes
- `enable_memory` - Habilitar memÃ³ria hierÃ¡rquica
- `checkpoint_retention` - Dias de retenÃ§Ã£o de checkpoints
- `max_checkpoints` - MÃ¡ximo de checkpoints armazenados
- `log_level` - NÃ­vel de log: `debug`, `info`, `warn`, `error`
- `log_file` - Arquivo de log (vazio = nÃ£o salvar)

### 3. Performance (OtimizaÃ§Ãµes)

```json
{
  "performance": {
    "cache_ttl": 15,
    "enable_cache": true,
    "max_concurrent_tools": 3,
    "command_timeout": 60
  }
}
```

**Campos:**
- `cache_ttl` - Tempo de vida do cache em minutos
- `enable_cache` - Habilitar cache de contexto
- `max_concurrent_tools` - MÃ¡ximo de ferramentas executando em paralelo
- `command_timeout` - Timeout de comandos shell em segundos

## ğŸ¯ Uso

### 1. Usar configuraÃ§Ã£o padrÃ£o

```bash
ollama-code chat
```

O sistema automaticamente:
- Procura `~/.ollama-code/config.json`
- Se nÃ£o existe, cria com valores padrÃ£o
- Carrega e valida configuraÃ§Ã£o

### 2. Especificar arquivo customizado

```bash
ollama-code chat --config /path/to/custom-config.json
```

### 3. Sobrescrever com flags

As flags de linha de comando **sobrescrevem** o arquivo:

```bash
# Sobrescreve mode do config.json
ollama-code chat --mode autonomous

# Sobrescreve model e url
ollama-code chat --model llama3:8b --url http://192.168.1.100:11434

# MÃºltiplas sobrescritas
ollama-code chat --mode readonly --workdir /project
```

**Ordem de prioridade:**
1. **Flags CLI** (maior prioridade)
2. **Arquivo customizado** (--config)
3. **Arquivo padrÃ£o** (~/.ollama-code/config.json)
4. **Defaults hardcoded** (menor prioridade)

## ğŸ“‹ Exemplos de ConfiguraÃ§Ã£o

### ConfiguraÃ§Ã£o para Desenvolvimento

```json
{
  "ollama": {
    "url": "http://localhost:11434",
    "model": "qwen2.5-coder:7b",
    "temperature": 0.5,
    "max_tokens": 2048
  },
  "app": {
    "mode": "interactive",
    "enable_colors": true,
    "enable_checkpoints": true,
    "log_level": "debug",
    "log_file": "/tmp/ollama-code.log"
  },
  "performance": {
    "enable_cache": true,
    "max_concurrent_tools": 2,
    "command_timeout": 30
  }
}
```

### ConfiguraÃ§Ã£o para ProduÃ§Ã£o/Corporativo

```json
{
  "ollama": {
    "url": "http://ollama-server:11434",
    "model": "qwen2.5-coder:32b-instruct-q6_K",
    "temperature": 0.3,
    "max_tokens": 8192
  },
  "app": {
    "mode": "interactive",
    "output_style": "corporate",
    "enable_colors": false,
    "enable_checkpoints": true,
    "enable_sessions": true,
    "enable_memory": true,
    "checkpoint_retention": 90,
    "log_level": "info"
  },
  "performance": {
    "enable_cache": true,
    "max_concurrent_tools": 5,
    "command_timeout": 120
  }
}
```

### ConfiguraÃ§Ã£o Readonly (SeguranÃ§a)

```json
{
  "ollama": {
    "url": "http://localhost:11434",
    "model": "qwen2.5-coder:32b-instruct-q6_K"
  },
  "app": {
    "mode": "readonly",
    "enable_checkpoints": false,
    "enable_sessions": false,
    "log_level": "warn"
  },
  "performance": {
    "enable_cache": true,
    "max_concurrent_tools": 1
  }
}
```

## ğŸ”§ Comandos Ãšteis

### Ver configuraÃ§Ã£o atual
```bash
cat ~/.ollama-code/config.json | jq .
```

### Editar configuraÃ§Ã£o
```bash
# Linux/macOS
nano ~/.ollama-code/config.json

# Windows
notepad %USERPROFILE%\.ollama-code\config.json
```

### Resetar para padrÃµes
```bash
# Apagar arquivo - serÃ¡ recriado automaticamente
rm ~/.ollama-code/config.json
```

### Validar arquivo JSON
```bash
cat ~/.ollama-code/config.json | jq . > /dev/null && echo "âœ… JSON vÃ¡lido" || echo "âŒ JSON invÃ¡lido"
```

## âš ï¸ Notas Importantes

1. **Formato JSON estrito** - Use vÃ­rgulas corretamente, sem trailing commas
2. **Strings entre aspas duplas** - JSON requer `"` nÃ£o `'`
3. **Booleans em lowercase** - `true`/`false` nÃ£o `True`/`False`
4. **NÃºmeros sem aspas** - `999` nÃ£o `"999"`
5. **Paths em Windows** - Use `\\` ou `/` em paths: `"C:/Users/..."`

## ğŸ› Troubleshooting

### Config nÃ£o estÃ¡ sendo usado
```bash
# Verificar se arquivo existe
ls -la ~/.ollama-code/config.json

# Verificar permissÃµes
chmod 644 ~/.ollama-code/config.json

# ForÃ§ar uso de config customizado
ollama-code chat --config ./my-config.json
```

### Erro ao carregar config
```bash
# Validar JSON
cat config.json | jq .

# Ver mensagem de erro detalhada
ollama-code chat --config config.json 2>&1
```

### Valores nÃ£o estÃ£o sendo aplicados
```bash
# Flags CLI sobrescrevem config
# Remova flags para usar valores do arquivo
ollama-code chat  # Sem --mode, --model, etc
```

## ğŸ“š ReferÃªncia Completa

Veja `config.example.json` na raiz do projeto para um exemplo completo comentado.

---

**Pronto para configurar!** ğŸš€

Edite `~/.ollama-code/config.json` conforme suas necessidades.
